{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\") #.sample(1000, random_state=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, qid1, qid2, question1, question2, is_duplicate]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No exact duplicates\n",
    "df[df['question1'] == df['question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204021, 6)\n",
      "(51006, 6)\n",
      "(119410, 6)\n",
      "(29853, 6)\n"
     ]
    }
   ],
   "source": [
    "# Account for imbalance in data set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train_0, df_test_0 = train_test_split(df[df['is_duplicate'] == 0], train_size=0.8,random_state=0)\n",
    "df_train_1, df_test_1 = train_test_split(df[df['is_duplicate'] == 1], train_size=0.8,random_state=0)\n",
    "\n",
    "print(df_train_0.shape)\n",
    "print(df_test_0.shape)\n",
    "print(df_train_1.shape)\n",
    "print(df_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257849</th>\n",
       "      <td>257849</td>\n",
       "      <td>129883</td>\n",
       "      <td>373253</td>\n",
       "      <td>I enjoy tending to my self inflicted injuries....</td>\n",
       "      <td>Am I doing it wrong? Is there an alternative w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140751</th>\n",
       "      <td>140751</td>\n",
       "      <td>38090</td>\n",
       "      <td>223615</td>\n",
       "      <td>How do you say \"I'm sorry\" in Korean? Is there...</td>\n",
       "      <td>In Korean, how do you say \"work\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277047</th>\n",
       "      <td>277047</td>\n",
       "      <td>396077</td>\n",
       "      <td>396078</td>\n",
       "      <td>What are advantages of projector head lights o...</td>\n",
       "      <td>I'm looking for a new (or lightly used) car. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387603</th>\n",
       "      <td>387603</td>\n",
       "      <td>118351</td>\n",
       "      <td>46690</td>\n",
       "      <td>What's Linux?</td>\n",
       "      <td>What is the use of Linux?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74206</th>\n",
       "      <td>74206</td>\n",
       "      <td>127210</td>\n",
       "      <td>127211</td>\n",
       "      <td>Which design softwares does the aerospace indu...</td>\n",
       "      <td>Is the right to police to pull us in chowky if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "257849  257849  129883  373253   \n",
       "140751  140751   38090  223615   \n",
       "277047  277047  396077  396078   \n",
       "387603  387603  118351   46690   \n",
       "74206    74206  127210  127211   \n",
       "\n",
       "                                                question1  \\\n",
       "257849  I enjoy tending to my self inflicted injuries....   \n",
       "140751  How do you say \"I'm sorry\" in Korean? Is there...   \n",
       "277047  What are advantages of projector head lights o...   \n",
       "387603                                      What's Linux?   \n",
       "74206   Which design softwares does the aerospace indu...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "257849  Am I doing it wrong? Is there an alternative w...             0  \n",
       "140751                  In Korean, how do you say \"work\"?             0  \n",
       "277047  I'm looking for a new (or lightly used) car. I...             0  \n",
       "387603                          What is the use of Linux?             1  \n",
       "74206   Is the right to police to pull us in chowky if...             0  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train_0, df_train_1]).sample(frac=1)\n",
    "df_test = pd.concat([df_test_0, df_test_1]).sample(frac=1)\n",
    "y_train = df_train['is_duplicate']\n",
    "y_test = df_test['is_duplicate']\n",
    "\n",
    "# Make sure no rows got dropped\n",
    "print(len(df_train)+len(df_test)==len(df))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Forest Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a subsample to test word processing functions\n",
    "df.loc[0:2,['question1', 'question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-11-17 9:05 Attempt with a single call of .apply; no good\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import string\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# def process_doc(doc):\n",
    "    \n",
    "#     values = doc\n",
    "#     # print(type(doc))\n",
    "#     print(values,'\\n\\n')\n",
    "#     # # remove special characters\n",
    "#     # doc = ''.join([char for char in doc if not char in string.punctuation])\n",
    "\n",
    "#     # # Split text into single words (also gets rid of extra white spaces)\n",
    "#     # words = word_tokenize(doc)\n",
    "\n",
    "#     # # Convert to lower case\n",
    "#     # words = [word.lower() for word in words]\n",
    "    \n",
    "#     # # # Remove stop words aside from the 5 why's + how\n",
    "#     # stop_words = set(stopwords.words('english')) - set(['who', 'what', 'where', 'when', 'how', 'why'])\n",
    "#     # words = [w for w in words if not w in stop_words]\n",
    "\n",
    "#     # # Stem\n",
    "#     # # porter = PorterStemmer()\n",
    "#     # # words = [porter.stem(word) for word in words]\n",
    "#     # wnl = WordNetLemmatizer()\n",
    "#     # words = [wnl.lemmatize(word) for word in words]\n",
    "\n",
    "#     # return words\n",
    "\n",
    "# # %%timeit\n",
    "# def process_pairs(df):\n",
    "#     df = df.apply(lambda x: process_doc(x))\n",
    "\n",
    "#     # return df\n",
    "\n",
    "\n",
    "# process_pairs(df.loc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>length_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[what, step, step, guide, invest, share, marke...</td>\n",
       "      <td>[what, step, step, guide, invest, share, market]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[what, story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[what, would, happen, indian, government, stol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[how, increase, speed, internet, connection, u...</td>\n",
       "      <td>[how, internet, speed, increased, hacking, dns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate                                          question1  \\\n",
       "0             0  [what, step, step, guide, invest, share, marke...   \n",
       "1             0         [what, story, kohinoor, kohinoor, diamond]   \n",
       "2             0  [how, increase, speed, internet, connection, u...   \n",
       "\n",
       "                                           question2  length_diff  \n",
       "0   [what, step, step, guide, invest, share, market]            0  \n",
       "1  [what, would, happen, indian, government, stol...            0  \n",
       "2    [how, internet, speed, increased, hacking, dns]            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # 2022-11-17 8:49 multiple .apply\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import string\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# def process_doc(doc):\n",
    "\n",
    "#     # remove special characters\n",
    "#     doc = ''.join([char for char in doc if not char in string.punctuation])\n",
    "\n",
    "#     # Split text into single words (also gets rid of extra white spaces)\n",
    "#     words = word_tokenize(doc)\n",
    "\n",
    "#     # Convert to lower case\n",
    "#     words = [word.lower() for word in words]\n",
    "    \n",
    "#     # # Remove stop words aside from the 5 why's + how\n",
    "#     stop_words = set(stopwords.words('english')) - set(['who', 'what', 'where', 'when', 'how', 'why'])\n",
    "#     words = [w for w in words if not w in stop_words]\n",
    "\n",
    "#     # Stem\n",
    "#     # porter = PorterStemmer()\n",
    "#     # words = [porter.stem(word) for word in words]\n",
    "#     wnl = WordNetLemmatizer()\n",
    "#     words = [wnl.lemmatize(word) for word in words]\n",
    "\n",
    "#     return words\n",
    "\n",
    "# # %%timeit\n",
    "# def process_pairs(df):\n",
    "#     tokens1 = df['question1'].apply(lambda x: process_doc(x))\n",
    "#     tokens2 = df['question2'].apply(lambda x: process_doc(x))\n",
    "\n",
    "#     df2 = pd.concat([df['is_duplicate'], \n",
    "#         tokens1,\n",
    "#         tokens2\n",
    "#         ], axis=1)\n",
    "\n",
    "#     df2['length_diff'] = abs(len(tokens1) - len(tokens2))\n",
    "\n",
    "#     return df2\n",
    "\n",
    "\n",
    "# process_pairs(df.loc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'which',\n",
       " 'while',\n",
       " 'whom',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english')) - set(['who', 'what', 'where', 'when', 'how', 'why'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1 length</th>\n",
       "      <th>Q2 length</th>\n",
       "      <th>length ratio</th>\n",
       "      <th>N common words</th>\n",
       "      <th>common words percentage</th>\n",
       "      <th>same last word</th>\n",
       "      <th>not_count1</th>\n",
       "      <th>N common non-stop words</th>\n",
       "      <th>common non-stop words percentage</th>\n",
       "      <th>Q1 Q1 length difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1 length  Q2 length  length ratio  N common words  \\\n",
       "0       14.0       12.0      0.857143            11.0   \n",
       "1        8.0       13.0      0.615385             4.0   \n",
       "2       14.0       10.0      0.714286             4.0   \n",
       "3       11.0        9.0      0.818182             0.0   \n",
       "4       13.0        7.0      0.538462             4.0   \n",
       "\n",
       "   common words percentage  same last word  not_count1  \\\n",
       "0                 0.785714             0.0         0.0   \n",
       "1                 0.307692             0.0         0.0   \n",
       "2                 0.285714             0.0         0.0   \n",
       "3                 0.000000             0.0         0.0   \n",
       "4                 0.307692             0.0         0.0   \n",
       "\n",
       "   N common non-stop words  common non-stop words percentage  \\\n",
       "0                      6.0                          0.750000   \n",
       "1                      3.0                          0.300000   \n",
       "2                      3.0                          0.428571   \n",
       "3                      0.0                          0.000000   \n",
       "4                      2.0                          0.200000   \n",
       "\n",
       "   Q1 Q1 length difference  \n",
       "0                      2.0  \n",
       "1                      5.0  \n",
       "2                      4.0  \n",
       "3                      2.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forest models\n",
    "    # Data prep using .itertuples()\n",
    "# %%time\n",
    "\n",
    "def process_doc(doc):\n",
    "\n",
    "    # remove special characters\n",
    "    doc = ''.join([char for char in doc if not char in string.punctuation])\n",
    "\n",
    "    # Split text into single words (also gets rid of extra white spaces)\n",
    "    words = word_tokenize(doc)\n",
    "\n",
    "    # Convert to lower case\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Stem\n",
    "    # porter = PorterStemmer()\n",
    "    # words = [porter.stem(word) for word in words]\n",
    "    wnl = WordNetLemmatizer()\n",
    "    words = [wnl.lemmatize(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "# feature engineering\n",
    "def process_pairs(df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on pairs of questions for forest models.\n",
    "    \"\"\"\n",
    "\n",
    "    length_diff = []\n",
    "    n_common_words = []\n",
    "    df2 = pd.DataFrame()\n",
    "    for index, q1, q2 in df[['question1', 'question2']].itertuples():\n",
    "        # Preprocess\n",
    "        tokens1 = process_doc(q1)\n",
    "        tokens2 = process_doc(q2)\n",
    "        # print(tokens1)\n",
    "        # print(tokens2)\n",
    "        # print()\n",
    "\n",
    "        # Get number of words for q1 and a2 and the ratio of these values\n",
    "        df2.loc[index,'Q1 length'] = int(len(tokens1))\n",
    "        df2.loc[index,'Q2 length'] = len(tokens2)\n",
    "        df2.loc[index,'length ratio'] = min([len(tokens1), len(tokens2)]) / max([len(tokens1), len(tokens2)])\n",
    "\n",
    "        # Number of common words between q1 and q2\n",
    "        common_words = set(tokens1) & set(tokens2)\n",
    "        df2.loc[index,'N common words'] = len(common_words)\n",
    "\n",
    "        # Common words between q1 and q2 as a percentage of longest question in the pair\n",
    "        df2.loc[index,'common words percentage'] = len(common_words) / max([len(tokens1), len(tokens2)])\n",
    "\n",
    "        # Same last word\n",
    "        df2.loc[index,'same last word'] = int(tokens1[-1] == tokens2[-1])\n",
    "\n",
    "        # Same frequency of the word 'not'\n",
    "        df2.loc[index,'not_count1'] = sum(word=='not' for word in tokens1)\n",
    "    \n",
    "        # # Remove stop words aside from the 5 why's + how\n",
    "        stop_words = set(stopwords.words('english')) - set(['who', 'what', 'where', 'when', 'how', 'why'])\n",
    "        words1 = [w for w in tokens1 if not w in stop_words]\n",
    "        words2 = [w for w in tokens2 if not w in stop_words]\n",
    "\n",
    "        # Number of common words between q1 and q2 with stop words removed\n",
    "        common_words_nonstop = set(words1) & set(words2)\n",
    "        df2.loc[index,'N common non-stop words'] = len(common_words_nonstop)\n",
    "        df2.loc[index,'common non-stop words percentage'] = len(common_words_nonstop) / max(\n",
    "            [len(words1), len(words2)])\n",
    "        \n",
    "        # print(words2,'\\n')\n",
    "        \n",
    "    # length difference\n",
    "    df2['Q1 Q1 length difference'] = abs(df2['Q1 length'] - df2['Q2 length'])\n",
    "\n",
    "    return df2\n",
    "        \n",
    "\n",
    "process_pairs(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['why', 'do', 'slav', 'squat']\n",
      "['will', 'squat', 'make', 'my', 'leg', 'thicker']\n",
      "\n",
      "['when', 'can', 'i', 'expect', 'my', 'cognizant', 'confirmation', 'mail']\n",
      "['when', 'can', 'i', 'expect', 'cognizant', 'confirmation', 'mail']\n",
      "\n",
      "['can', 'i', 'make', '50000', 'a', 'month', 'by', 'day', 'trading']\n",
      "['can', 'i', 'make', '30000', 'a', 'month', 'by', 'day', 'trading']\n",
      "\n",
      "['is', 'being', 'a', 'good', 'kid', 'and', 'not', 'being', 'a', 'rebel', 'worth', 'it', 'in', 'the', 'long', 'run']\n",
      "['is', 'being', 'bored', 'good', 'for', 'a', 'kid']\n",
      "\n",
      "['what', 'university', 'doe', 'rexnord', 'recruit', 'new', 'grad', 'from', 'what', 'major', 'are', 'they', 'looking', 'for']\n",
      "['what', 'university', 'doe', 'bg', 'food', 'recruit', 'new', 'grad', 'from', 'what', 'major', 'are', 'they', 'looking', 'for']\n",
      "\n",
      "['what', 'is', 'the', 'quickest', 'way', 'to', 'increase', 'instagram', 'follower']\n",
      "['how', 'can', 'we', 'increase', 'our', 'number', 'of', 'instagram', 'follower']\n",
      "\n",
      "['how', 'did', 'darth', 'vader', 'fought', 'darth', 'maul', 'in', 'star', 'war', 'legend']\n",
      "['doe', 'quora', 'have', 'a', 'character', 'limit', 'for', 'profile', 'description']\n",
      "\n",
      "['what', 'are', 'the', 'stage', 'of', 'breaking', 'up', 'between', 'couple', 'i', 'mean', 'what', 'happens', 'after', 'the', 'breaking', 'up', 'emotionally', 'whether', 'it', 'a', 'male', 'or', 'female']\n",
      "['who', 'is', 'affected', 'more', 'by', 'a', 'breakup', 'the', 'boy', 'or', 'the', 'girl']\n",
      "\n",
      "['what', 'are', 'some', 'example', 'of', 'product', 'that', 'can', 'be', 'make', 'from', 'crude', 'oil']\n",
      "['what', 'are', 'some', 'of', 'the', 'product', 'made', 'from', 'crude', 'oil']\n",
      "\n",
      "['how', 'do', 'i', 'make', 'friend']\n",
      "['how', 'to', 'make', 'friend']\n",
      "\n",
      "['is', 'career', 'launcher', 'good', 'for', 'rbi', 'grade', 'b', 'preparation']\n",
      "['how', 'is', 'career', 'launcher', 'online', 'program', 'for', 'rbi', 'grade', 'b']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1 length</th>\n",
       "      <th>Q2 length</th>\n",
       "      <th>length ratio</th>\n",
       "      <th>N common words</th>\n",
       "      <th>common words percentage</th>\n",
       "      <th>same last word</th>\n",
       "      <th>not_count1</th>\n",
       "      <th>N common non-stop words</th>\n",
       "      <th>common non-stop words percentage</th>\n",
       "      <th>Q1 Q1 length difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Q1 length  Q2 length  length ratio  N common words  \\\n",
       "40        4.0        6.0      0.666667             1.0   \n",
       "41        8.0        7.0      0.875000             7.0   \n",
       "42        9.0        9.0      1.000000             8.0   \n",
       "43       16.0        7.0      0.437500             5.0   \n",
       "44       14.0       15.0      0.933333            12.0   \n",
       "45        9.0        9.0      1.000000             3.0   \n",
       "46       11.0        9.0      0.818182             0.0   \n",
       "47       24.0       12.0      0.500000             3.0   \n",
       "48       13.0       10.0      0.769231             8.0   \n",
       "49        5.0        4.0      0.800000             3.0   \n",
       "50        9.0       10.0      0.900000             7.0   \n",
       "\n",
       "    common words percentage  same last word  not_count1  \\\n",
       "40                 0.166667             0.0         0.0   \n",
       "41                 0.875000             1.0         0.0   \n",
       "42                 0.888889             1.0         0.0   \n",
       "43                 0.312500             0.0         1.0   \n",
       "44                 0.800000             1.0         0.0   \n",
       "45                 0.333333             1.0         0.0   \n",
       "46                 0.000000             0.0         0.0   \n",
       "47                 0.125000             0.0         0.0   \n",
       "48                 0.615385             1.0         0.0   \n",
       "49                 0.600000             1.0         0.0   \n",
       "50                 0.700000             0.0         0.0   \n",
       "\n",
       "    N common non-stop words  common non-stop words percentage  \\\n",
       "40                      1.0                          0.250000   \n",
       "41                      5.0                          1.000000   \n",
       "42                      4.0                          0.800000   \n",
       "43                      2.0                          0.333333   \n",
       "44                      8.0                          0.727273   \n",
       "45                      3.0                          0.500000   \n",
       "46                      0.0                          0.000000   \n",
       "47                      0.0                          0.000000   \n",
       "48                      4.0                          0.666667   \n",
       "49                      3.0                          1.000000   \n",
       "50                      5.0                          0.625000   \n",
       "\n",
       "    Q1 Q1 length difference  \n",
       "40                      2.0  \n",
       "41                      1.0  \n",
       "42                      0.0  \n",
       "43                      9.0  \n",
       "44                      1.0  \n",
       "45                      0.0  \n",
       "46                      2.0  \n",
       "47                     12.0  \n",
       "48                      3.0  \n",
       "49                      1.0  \n",
       "50                      1.0  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_pairs(df.loc[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "# Create a class named ClfSwitcher which inherits the base class called BaseEstimator from sklearn.\n",
    "    def __init__(self, estimator = LogisticRegression()):\n",
    "            self.estimator = estimator # receives an estimator (model) as an input\n",
    "            \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "            self.estimator.fit(X, y)\n",
    "            return self\n",
    "            \n",
    "    def predict(self, X, y=None):\n",
    "            return self.estimator.predict(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "            return self.estimator.predict_proba(X)\n",
    "            \n",
    "    def score(self, X, y):\n",
    "            return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('process_pairs',\n",
      "                 FunctionTransformer(func=<function process_pairs at 0x00000291C62F2F70>)),\n",
      "                ('model',\n",
      "                 ClfSwitcher(estimator=RandomForestClassifier(n_estimators=150,\n",
      "                                                              random_state=0)))])\n",
      "{'model__estimator': RandomForestClassifier(n_estimators=150, random_state=0), 'model__estimator__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "forest_pipe = Pipeline([\n",
    "    ('process_pairs', FunctionTransformer(process_pairs)),\n",
    "    ('model', ClfSwitcher())\n",
    "])\n",
    "# forest_pipe.fit_transform(df.head()) # This line works before the modeling step\n",
    "grid_params = [\n",
    "    {\n",
    "        'model__estimator': [LogisticRegression(random_state=0)],\n",
    "        'model__estimator__class_weight': [None, 'balanced']\n",
    "        },\n",
    "    {\n",
    "        'model__estimator': [SVC(random_state=0)],\n",
    "        'model__estimator__class_weight': [None, 'balanced']\n",
    "        },\n",
    "    {\n",
    "        'model__estimator': [xgb.XGBClassifier(random_state=0)]},\n",
    "        'model__estimator__n_estimators': [100, 150, 200],\n",
    "        {\n",
    "        'model__estimator': [RandomForestClassifier(random_state=0)],\n",
    "        'model__estimator__n_estimators': [100, 150, 200]\n",
    "        },\n",
    "    ]\n",
    "gs = GridSearchCV(forest_pipe, grid_params, scoring='accuracy')\n",
    "gs.fit(df.head(20), df.head(20)['is_duplicate'])\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_params_)\n",
    "y_pred = gs.predict(df.head(10)) # 2022-11-17 11:56 works for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0]\n",
      "[0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(list(df.head(20)['is_duplicate']))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cloudEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86576fc1f72bb8252e2f1578cc878ed2c12b40840637cdef083c8fb979cf67d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
